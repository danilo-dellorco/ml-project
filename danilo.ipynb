{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Introduzione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'obiettivo è quello di analizzare il dataset sui funghi, e testare diversi classificatori per trovare il migliore nel classificare nuovi funghi come commestibili o velenosi. Il documento è composto come segue:\n",
    "\n",
    "- Data Exploration\n",
    "    - Analisi classi dataset\n",
    "    - Feature Selection\n",
    "    - Rimozione righe malformate\n",
    "- Test Classificatori\n",
    "    - Naive Bayes\n",
    "    - Random Forest\n",
    "    - ...\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import delle librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "#altri import futuri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caricamento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>icu_admit_source</th>\n",
       "      <th>...</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "      <th>Unnamed: 83</th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66154</td>\n",
       "      <td>25312</td>\n",
       "      <td>118</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>180.3</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114252</td>\n",
       "      <td>59342</td>\n",
       "      <td>81</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119783</td>\n",
       "      <td>50777</td>\n",
       "      <td>118</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.95</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>172.7</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79267</td>\n",
       "      <td>46918</td>\n",
       "      <td>118</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.64</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>165.1</td>\n",
       "      <td>Operating Room / Recovery</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92056</td>\n",
       "      <td>34377</td>\n",
       "      <td>33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_id  hospital_id   age    bmi  elective_surgery  \\\n",
       "0         66154       25312          118  68.0  22.73                 0   \n",
       "1        114252       59342           81  77.0  27.42                 0   \n",
       "2        119783       50777          118  25.0  31.95                 0   \n",
       "3         79267       46918          118  81.0  22.64                 1   \n",
       "4         92056       34377           33  19.0    NaN                 0   \n",
       "\n",
       "   ethnicity gender  height           icu_admit_source  ...  \\\n",
       "0  Caucasian      M   180.3                      Floor  ...   \n",
       "1  Caucasian      F   160.0                      Floor  ...   \n",
       "2  Caucasian      F   172.7       Accident & Emergency  ...   \n",
       "3  Caucasian      F   165.1  Operating Room / Recovery  ...   \n",
       "4  Caucasian      M   188.0       Accident & Emergency  ...   \n",
       "\n",
       "   diabetes_mellitus hepatic_failure immunosuppression  leukemia  lymphoma  \\\n",
       "0                1.0             0.0               0.0       0.0       0.0   \n",
       "1                1.0             0.0               0.0       0.0       0.0   \n",
       "2                0.0             0.0               0.0       0.0       0.0   \n",
       "3                0.0             0.0               0.0       0.0       0.0   \n",
       "4                0.0             0.0               0.0       0.0       0.0   \n",
       "\n",
       "   solid_tumor_with_metastasis  apache_3j_bodysystem  apache_2_bodysystem  \\\n",
       "0                          0.0                Sepsis       Cardiovascular   \n",
       "1                          0.0           Respiratory          Respiratory   \n",
       "2                          0.0             Metabolic            Metabolic   \n",
       "3                          0.0        Cardiovascular       Cardiovascular   \n",
       "4                          0.0                Trauma               Trauma   \n",
       "\n",
       "   Unnamed: 83  hospital_death  \n",
       "0          NaN               0  \n",
       "1          NaN               0  \n",
       "2          NaN               0  \n",
       "3          NaN               0  \n",
       "4          NaN               0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset/dataset.csv\", sep=\",\")\n",
    "dataset_bak = dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Class Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siamo interessati a classificare i pazienti ricoverati come 'in pericolo di vita' oppure 'in salute'. Per questo motivo identifichiamo le due classi di interesse a partire dalla colonna ```hospital_death``` del dataset. Vogliamo vedere quanto sono bilanciate le classi del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [{\"Survived\": (dataset[\"hospital_death\"] == 0).sum(), \"Dead\": (dataset[\"hospital_death\"] == 1).sum()}]\n",
    "total  = pd.DataFrame(classes)\n",
    "total_e = float(total[\"Survived\"])\n",
    "total_p = float(total[\"Dead\"])\n",
    "mushrooms = [total_e, total_p]\n",
    "mushrooms_labels = 'Survived','Dead'\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "plt.pie(mushrooms,labels=mushrooms,autopct='%1.1f%%',colors = ['#88d14f', '#f23d3a'])\n",
    "plt.title('Dataset Balancing', loc = \"center\", fontsize=\"20\")\n",
    "plt.axis('equal')\n",
    "plt.legend(mushrooms_labels,bbox_to_anchor=(0.6, -0.05, 0, 0))\n",
    "fig.set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come possiamo vedere il dataset è altamente sbilanciato. Infatti abbiamo il 91.4% di righe che riportano dati per un paziente sopravvissuto, mentre solo l'8.6% di dati per un paziente deceduto. Ciò implica dire che qualsiasi modello allenato su un training set ricavato da tale dataset tenderà maggiormente a classificare un'istanza come 'survived', aspettandoci quindi molti falsi negativi. (Positivo = death, Negativo = survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualizzazione features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a visualizzare la distribuzione delle features all'interno del dataset, riportando in un barplot le variabili categoriche e in un histplot le variabili numeriche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['xkcd:pale orange', 'xkcd:sea blue', 'xkcd:pale red', 'xkcd:sage green', 'xkcd:terra cotta', 'xkcd:dull purple', 'xkcd:teal', 'xkcd:goldenrod', 'xkcd:cadet blue', \n",
    "          'xkcd:scarlet']\n",
    "ignore = ['encounter_id','patient_id','Unnamed: 83','hospital_id','icu_id','hospital_death']\n",
    "categ = []\n",
    "numer = []\n",
    "\n",
    "for col in dataset.drop(columns=ignore): \n",
    "    dt = dataset[col].dtype\n",
    "    if dt == \"object\":\n",
    "        categ.append(col)\n",
    "    elif dt == \"float64\":\n",
    "        if dataset[col].dropna().nunique()<10:\n",
    "            dataset[col] = dataset[col].astype('object')\n",
    "            categ.append(col)\n",
    "        else:\n",
    "            numer.append(col)\n",
    "    elif dt == \"int64\":\n",
    "        dataset[col] = dataset[col].astype('object')\n",
    "        categ.append(col)\n",
    "\n",
    "fig = plt.figure(figsize=(120,120))\n",
    "j=1\n",
    "a=0\n",
    "b=0\n",
    "for i in range(0, len(dataset.columns)-len(ignore)):\n",
    "    col = dataset.columns[i]\n",
    "\n",
    "    if col in categ:\n",
    "        fig.add_subplot(10,10,j)\n",
    "        ax = sns.countplot(x=categ[a], data=dataset, alpha=.7, order=sorted(dataset[col].dropna().unique().tolist(),key=str))\n",
    "        ax.bar_label(ax.containers[0])\n",
    "        ax.set_xticklabels(ax.get_xticklabels(),rotation = 45)\n",
    "        j += 1\n",
    "        a += 1\n",
    "\n",
    "    elif col in numer:\n",
    "        fig.add_subplot(10,10,j)\n",
    "        sns.histplot(dataset[numer[b]].dropna(), kde_kws={\"lw\": 2, \"color\":colors[8]})\n",
    "        j += 1\n",
    "        b += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualizzazione campi non nulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizzazione campi non nulli per ogni colonna/feature del dataset. Questo ci serve per vedere eventuali colonne che possono poi essere rimosse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nas(datasetX, use_threshold, threshold=None):\n",
    "    to_delete = []\n",
    "    if datasetX.isnull().sum().sum() != 0:\n",
    "        na_datasetX = (datasetX.isnull().sum() / len(datasetX)) * 100\n",
    "        na_datasetX = na_datasetX.drop(na_datasetX[na_datasetX == 0].index).sort_values(ascending=False)\n",
    "        to_delete = na_datasetX[na_datasetX > threshold]\n",
    "\n",
    "        missing_data = pd.DataFrame({'Null Ratio %' :na_datasetX})\n",
    "        missing_data.plot(kind = \"barh\")\n",
    "        plt.rcParams['figure.figsize'] = (20,20)\n",
    "\n",
    "        if use_threshold:\n",
    "            plt.axvline(x=threshold, color='red')\n",
    "            #plt.text(threshold-2,-1.5,'thr = 50', color = 'red')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print('No NAs found')\n",
    "        return None\n",
    "    \n",
    "    if use_threshold:\n",
    "        print(to_delete.index.tolist())\n",
    "    return to_delete.index.tolist()\n",
    "        \n",
    "\n",
    "p = plot_nas(dataset,use_threshold=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizzando la distribuzione delle varie features possiamo vedere come il dataset sia di buona qualità, avendo pochi campi non nulli. Tuttavia la feature ```Unnamed: 83``` presenta soltanto campi nulli, e quindi verrà eliminata in una successiva fase di pulizia del dataset.\n",
    "\n",
    "Le restanti features presentano valori `NaN` per una percentuale sempre inferiore al 20%, motivo per cui possiamo procedere con una imputazione di tali dati, senza introdurre un rumore eccessivo nel dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conversione Features e Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversione delle features categoriche in nominali, si modifica prima il tipo di dato dei valori delle features da ```object``` in ```category``` per poi procedere con l'effettiva trasformazione dei valori categorici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si trasformano i valori categorici in numerici (int64) e si salva il dizionario che mantiene il mapping per un eventuale utilizzo futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_dataset = dataset.copy()\n",
    "encoder = LabelEncoder()\n",
    "mapping = []\n",
    "\n",
    "for i in range(len(mapped_dataset.columns)):\n",
    "    \n",
    "    if (mapped_dataset[mapped_dataset.columns[i]].dtype == \"object\"):\n",
    "            mapped_dataset[mapped_dataset.columns[i]] = encoder.fit_transform(mapped_dataset[mapped_dataset.columns[i]])\n",
    "            mapping_dict = {index : label for index , label in enumerate(encoder.classes_)}\n",
    "            mapping.append(mapping_dict)\n",
    "\n",
    "mapped_dataset = mapped_dataset.where(~dataset.isna(), dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo il mapping effettuato delle variabili categoriche.\n",
    "\n",
    "- _NOTA_: I valori `NaN` risultano mappati nel dizionario, ma tramite la clausola ```where(~dataset.isna(), dataset)``` ristabiliamo i valori NaN originali per la successiva fase di imputazione dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completiamo trasformando il tipo di dato associato alle features categoriche da ```object``` in ```float64```, oggetto che accetta valori interi nulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in mapped_dataset.columns:\n",
    "    if (mapped_dataset[el].dtype == \"object\"):\n",
    "        mapped_dataset[el] = np.floor(pd.to_numeric(mapped_dataset[el], errors='coerce')).astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo che abbiamo mappato le nostre variabili categoriche in variabili ordinali. I valori nulli sono stati mantenuti <NaN> per una successiva fase di imputazione. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo il grado di correlazione reciproco tra le varie feature, compresa la correlazione di ogni feature con il target. In generale vogliamo che una feature sia altamente correlata con il target (quindi che il suo valore sia importante per discriminare se il paziente sopravvive o muore). Una correlazione alta è sia positiva (aumento del valore di uno aumenta il valore dell'altro) che negativa (aumento del valore di uno diminuisce il valore dell'altro). Una correlazione vicina allo zero implica che le variabili sono indipendenti tra loro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32,24))\n",
    "correlation_matrix = mapped_dataset.drop(columns=\"Unnamed: 83\").corr('spearman')\n",
    "sns.heatmap(correlation_matrix, linewidths=0.05, cmap=\"PiYG\", annot=True, annot_kws={\"fontsize\":4})\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizziamo alcune tra le features più rilevanti rispetto al target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilità di morte in relazione all'età"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "age_death_F=dataset[dataset['gender']=='F'][['age','hospital_death']].groupby('age').mean().reset_index()\n",
    "age_death_M=dataset[dataset['gender']=='M'][['age','hospital_death']].groupby('age').mean().reset_index()\n",
    "fig,ax = plt.subplots(figsize = (12,8))\n",
    "# name=\"Female patients\"\n",
    "sns.lineplot(x=age_death_F['age'], y=age_death_F['hospital_death'])\n",
    "# name=\"Male patients\"\n",
    "sns.lineplot(x=age_death_M['age'], y=age_death_M['hospital_death'])\n",
    "plt.title(\"Average hospital death probability of patients\", fontsize = 20)\n",
    "\n",
    "plt.legend(['Female',\"Male\"])\n",
    "plt.xlabel(\"Patient Age\")\n",
    "plt.ylabel(\"Average Hospital Death\")\n",
    "fig.show()\n",
    "\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come atteso, l'età risulta essere un fattore determinante nella mortalità dei pazienti ricoverati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilità di morte in relazione al BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df=dataset[['hospital_death','bmi']]\n",
    "\n",
    "df['bmi'] = df['bmi'].round(0)\n",
    "bmi_death=df[['bmi','hospital_death']].groupby('bmi').mean().reset_index()\n",
    "fig,ax = plt.subplots(figsize = (12,8))\n",
    "sns.lineplot(x=bmi_death['bmi'], y=bmi_death['hospital_death'])\n",
    "plt.title(\"Impacts of BMI over patients\", fontsize = 20)\n",
    "\n",
    "plt.xlabel(\"BMI\")\n",
    "plt.ylabel(\"Average Hospital Death\")\n",
    "fig.show()\n",
    "\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il BMI impatta notevolmente nella mortalità, infatti un valore troppo basso o troppo aumenta la probabilità di decesso  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilità di morte in relazione a score apache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilità di morte in relazione a malattie critiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "critical = ['hospital_death','aids','cirrhosis','diabetes_mellitus','hepatic_failure','immunosuppression','leukemia']\n",
    "df=dataset[critical]\n",
    "\n",
    "aids_death=df[['aids','hospital_death']].groupby('aids').mean().reset_index()\n",
    "cirrhosis_death=df[['cirrhosis','hospital_death']].groupby('cirrhosis').mean().reset_index()\n",
    "diabetes_mellitus_death=df[['diabetes_mellitus','hospital_death']].groupby('diabetes_mellitus').mean().reset_index()\n",
    "hepatic_failure_death=df[['hepatic_failure','hospital_death']].groupby('hepatic_failure').mean().reset_index()\n",
    "immunosuppression_death=df[['immunosuppression','hospital_death']].groupby('immunosuppression').mean().reset_index()\n",
    "leukemia_death=df[['leukemia','hospital_death']].groupby('leukemia').mean().reset_index()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30,15))\n",
    "\n",
    "fig.add_subplot(2,3,1)\n",
    "sns.barplot(x=aids_death['aids'], y=aids_death['hospital_death'])\n",
    "plt.title(\"Impacts of AIDS over Patients\", fontsize = 20)\n",
    "plt.xlabel(\"AIDS\")\n",
    "plt.ylabel(\"Average Hospital Death\")\n",
    "\n",
    "fig.add_subplot(2,3,2)\n",
    "sns.barplot(x=cirrhosis_death['cirrhosis'], y=cirrhosis_death['hospital_death'])\n",
    "plt.title(\"Impacts of Cirrhosis over Patients\", fontsize = 20)\n",
    "plt.xlabel(\"Cirrhosis\")\n",
    "plt.ylabel(\"Average Hospital Death\")\n",
    "\n",
    "fig.add_subplot(2,3,3)\n",
    "sns.barplot(x=diabetes_mellitus_death['diabetes_mellitus'], y=diabetes_mellitus_death['hospital_death'])\n",
    "plt.title(\"Impacts of Diabetes Mellitus over Patients\", fontsize = 20)\n",
    "plt.xlabel(\"Diabetes Mellitus\")\n",
    "plt.ylabel(\"Average Hospital Death\")\n",
    "\n",
    "fig.add_subplot(2,3,4)\n",
    "sns.barplot(x=hepatic_failure_death['hepatic_failure'], y=hepatic_failure_death['hospital_death'])\n",
    "plt.title(\"Impacts of Hepatitic Failure over Patients\", fontsize = 20)\n",
    "plt.xlabel(\"Hepatitic Failure\")\n",
    "plt.ylabel(\"Average Hospital Death\")\n",
    "\n",
    "fig.add_subplot(2,3,5)\n",
    "sns.barplot(x=immunosuppression_death['immunosuppression'], y=immunosuppression_death['hospital_death'])\n",
    "plt.title(\"Impacts of Immunosuppression over Patients\", fontsize = 20)\n",
    "plt.xlabel(\"Immunosuppression\")\n",
    "plt.ylabel(\"Average Hospital Death\")\n",
    "\n",
    "fig.add_subplot(2,3,6)\n",
    "sns.barplot(x=leukemia_death['leukemia'], y=leukemia_death['hospital_death'])\n",
    "plt.title(\"Impacts of Leukemia over Patients\", fontsize = 20)\n",
    "plt.xlabel(\"Lekuemia\")\n",
    "plt.ylabel(\"Average Hospital Death\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "#TODO aggiungere lymphoma\n",
    "\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo come tutte queste variabili risultano importanti, in quanto incrementano la probabilità di decesso. L'unica eccezione è il Diabete, che risulta non impattare nella probabilità di decesso (bassa in entrambi i casi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hospital Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo se diverse strutture ospedaliere hanno maggiore o minore impatto sulla mortalità dei pazienti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(35,35))\n",
    "hospital_death=dataset[['hospital_id','hospital_death']].groupby('hospital_id').mean().reset_index()\n",
    "sns.barplot(x=hospital_death['hospital_id'], y=hospital_death['hospital_death'])\n",
    "plt.title(\"Impacts of Hospital over Patients\", fontsize = 20)\n",
    "plt.xlabel(\"Hospital\")\n",
    "plt.ylabel(\"Average Hospital Death\")\n",
    "plt.tick_params(labelsize = 8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osserviamo che alcuni ospedali sembrano avere probabilità di decesso elevate. Ad esempio l'ospedale ```131``` ha il 50% di decessi. Analizzando però il dataset possiamo vedere come in realtà ci siano soltanto due istanze relative all'ospedale 130, che è quindi un outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['hospital_id'].value_counts()[130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche l'ospedale ```51``` ha una probabilità più alta di decesso. Ma anche in questo caso possiamo vedere come siano pochi i dati (110) rispetto agli altri ospedali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['hospital_id'].value_counts()[51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Training & Test Set Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a splittare il dataset in training e stesting set. Utilizziamo come percentuali 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingSet: (73370, 84)\n",
      "TestingSet: (18343, 84)\n"
     ]
    }
   ],
   "source": [
    "targets = mapped_dataset['hospital_death']\n",
    "trainX, testX, trainY, testY = train_test_split(mapped_dataset.drop(columns = 'hospital_death'), targets, test_size = 0.2, random_state=0)\n",
    "print(\"TrainingSet:\",trainX.shape)\n",
    "print(\"TestingSet:\",testX.shape)\n",
    "\n",
    "trainX_og = trainX.copy()\n",
    "testX_og = testX.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Results on Original Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo a misurare le prestazioni di vari classificatori sul dataset originale, quindi senza ingegneria delle features e imputazione dei valori mancanti. \n",
    "- I classificatori considerati non gestiscono in modo automatico i valori ```NaN```\n",
    "- Per eseguire la classificazione è comunque necessario mappare i valori ```NaN``` su un qualche valore numerico\n",
    "- Si utilizza per questa fase di benchmark l'operatore ```fillna(-1)``` sostituendo quindi ```NaN``` con ```-1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifications(tr_x,train_Y,te_x,test_Y,fill=None,model=None,model_name=None):\n",
    "    train_X = tr_x.copy()\n",
    "    test_X = te_x.copy()\n",
    "\n",
    "    if fill:\n",
    "        train_X = train_X.fillna(-1)\n",
    "    \n",
    "    test_X = test_X.fillna(-1)\n",
    "    \n",
    "    if model == None:\n",
    "        lrc = LogisticRegression(solver=\"liblinear\")\n",
    "        rdt = DecisionTreeClassifier()\n",
    "        gnb = GaussianNB()\n",
    "\n",
    "        models = [(lrc, \"Logistic Regression Classifier\"),\n",
    "                  (rdt, \" Decision Tree Classifier\"),\n",
    "                  (gnb, \"Gaussian Naive Bayes Classifier\")]\n",
    "    else:\n",
    "        models = [(model,model_name)]\n",
    "\n",
    "    for model in models:\n",
    "        model[0].fit(train_X, train_Y)\n",
    "        predicted = model[0].predict(test_X)\n",
    "        print(model[1], \"report: \\n\\n\", classification_report(test_Y, predicted))\n",
    "        cm = confusion_matrix(test_Y, predicted)\n",
    "        x_axis_labels = [\"Survived\", \"Dead\"]\n",
    "        y_axis_labels = [\"Survived\", \"Dead\"]\n",
    "        f, ax = plt.subplots(figsize =(7,7))\n",
    "        sns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Reds\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "        plt.xlabel(\"PREDICTED LABEL\")\n",
    "        plt.ylabel(\"TRUE LABEL\")\n",
    "        plt.title('Confusion Matrix for Logistic Regression Classifier')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifications(trainX,trainY,testX,testY, fill = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Features Tweaking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andiamo ad eseguire diverse operazioni per rimuovere rumore dal dataset\n",
    "- Rimozione feature nulle e con bassa varianza\n",
    "- Feature Selection\n",
    "- PCA\n",
    "- Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Rimozione feature con valori nulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimuoviamo quelle colonne il cui valore percentuale di colonne nulle supera l'80%, e su cui risulterebbe inutile l'imputazione dei dati mancanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_del = plot_nas(trainX,use_threshold=True,threshold=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soltanto la feature Unnamed: 83 supera la soglia prefissata, per cui la rimuoviamo dal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.drop(columns=to_del)\n",
    "testX = testX.drop(columns=to_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Rimozione features con bassa varianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otteniamo la lista delle feature che presentano una varianza minore ad 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features to remove: ['gcs_unable_apache', 'aids', 'leukemia', 'lymphoma', 'Unnamed: 83']\n",
      "\n",
      "From 84 features to 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_variance_threshold.py:104: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  self.variances_ = np.nanvar(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "original_cols = trainX.columns.copy()\n",
    "threshold = 0.01\n",
    "\n",
    "selector = VarianceThreshold(threshold)\n",
    "selector.fit(trainX)\n",
    "features_to_remove = [x for x in original_cols if x not in selector.get_feature_names_out()]\n",
    "print(\"Features to remove: {}\\n\\nFrom {} features to {}\".format(features_to_remove, len(original_cols),len(selector.get_feature_names_out())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche se poco variabilòi 'gcs_unable_apache', 'aids', 'leukemia', 'lymphoma' sono importanti come visto nell'analisi delle feature quindi non andiamo a rimuoverle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminiamo le colonne selezionate dal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.drop(columns = features_to_remove)\n",
    "testX = testX.drop(columns = features_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Rimozione features con bassa correlazione col target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricaviamo le features che hanno una bassa correlazione con il target, inferiore ad una threshold di 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encounter_id', 'patient_id', 'hospital_id', 'ethnicity', 'gender', 'height', 'icu_admit_source', 'icu_id', 'icu_stay_type', 'icu_type', 'pre_icu_los_days', 'arf_apache', 'd1_diasbp_max', 'd1_diasbp_noninvasive_max', 'd1_heartrate_min', 'd1_mbp_max', 'd1_mbp_noninvasive_max', 'd1_temp_max', 'h1_spo2_max', 'd1_glucose_min', 'd1_potassium_min', 'aids', 'diabetes_mellitus', 'leukemia', 'lymphoma']\n"
     ]
    }
   ],
   "source": [
    "def get_low_correlated_features(threshold):\n",
    "    td = []\n",
    "    for feature in trainX.columns:\n",
    "        ind = trainX.columns.get_loc(feature)\n",
    "        target_corr = correlation_matrix.values[-1][ind]\n",
    "        if (target_corr>=-threshold and target_corr<0) or (target_corr<=threshold and target_corr>0):\n",
    "            td.append(feature)\n",
    "    return td\n",
    "\n",
    "to_delete = get_low_correlated_features(0.03)\n",
    "print(to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di queste variabili aids, leukemia e lymphoma sono comunque importanti nel dominio quindi non le andiamo a rimuovere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danil\\code\\ml-project\\danilo.ipynb Cella 80\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danil/code/ml-project/danilo.ipynb#ch0000143?line=0'>1</a>\u001b[0m to_delete\u001b[39m.\u001b[39;49mremove([\u001b[39m'\u001b[39;49m\u001b[39maids\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdiabetes_mellitus\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "to_delete.remove(['aids', 'leukemia','lymphoma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimuoviamo le feature individuate dal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.drop(columns=to_delete)\n",
    "testX = testX.drop(columns=to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eseguiamo la Backward Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_regression(X, y, threshold_out=0.05, verbose=True):\n",
    "    sf = []\n",
    "    included = list(X.columns)\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        changed = False\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max()  # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed = True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print(f\"worst_feature : {worst_feature}, {worst_pval} \")\n",
    "        if not changed:\n",
    "            break\n",
    "    sf.append(included)\n",
    "    print(f\"\\nSelected Features:\\n{sf[0]}\")\n",
    "    print(\"Feature Removed:\",len(X.columns) - len(included))\n",
    "    return sf\n",
    "    \n",
    "selected_features = backward_regression(trainX.fillna(-1), trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimuoviamo dal training set le feature non selezionate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.loc[:, selected_features[0]]\n",
    "testX = testX.loc[:, selected_features[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo che al termine della fase di pulizia abbiamo ridotto notevolmente la dimensionalità del dataset, passando da 84 a 39 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original:\", trainX_og.shape)\n",
    "print(\"Cleaned:\", trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confronto Prestazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confrontiamo le prestazioni ottenute nel training set originale con quelle a seguito della pulizia del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifications(trainX,trainY,testX,testY, fill = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Altri tentativi di Miglioramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizziamo ulteriori tecniche applicate per migliorare la qualità del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si utilizza un meccanismo di imputazione per sopperire alla presenza di dati mancanti delle diverse features del dataset. L'obiettivo è quello di ripristinare le diverse variabili per l'uso nella classificazione rimpiazzando tutti i dati nulli con valori derivati da entry simili nel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = KNNImputer(n_neighbors=1, weights='uniform')\n",
    "trainX_imp = pd.DataFrame(imp.fit_transform(trainX), columns = trainX.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizziamo i risultati a seguito della data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifications(trainX_imp,trainY,testX,testY, fill = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osserviamo che tutti gli score peggiorano. Questo perché si introduce comunque rumore nel dataset, e bisogna considerare che nel Dataset un valore assente potrebbe avere comunque un significato, ed è quindi errato andarlo a rimpiazzare. Utilizzando invece fillna(-1) si mantengono i NaN semplicemente mappandoli a -1, valore esclusivo non usato per altre variabili nel dizionario. (TODO vedere se tenere sta roba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PCA: Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cerchiamo di ridurre ulteriormente la dimensionalità del dataset applicando la Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "pca = PCA(n_components=int(trainX.shape[1]*0.7))\n",
    "trainX_pca = pd.DataFrame(pca.fit_transform(trainX.fillna(-1)))\n",
    "testX_pca = pd.DataFrame(pca.transform(testX.fillna(-1)))\n",
    "print(trainX_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizziamo i risultati a seguito di PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifications(trainX_pca,trainY,testX_pca,testY, fill = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come visto in precedenza il dataset risulta fortemente sbilanciato. Visualizziamo che anche a seguito dello splitting in training e testing set resta tale sbilanciamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [{\"Survived\": (trainY== 0).sum(), \"Dead\": (trainY== 1).sum()}]\n",
    "total  = pd.DataFrame(classes)\n",
    "total_e = float(total[\"Survived\"])\n",
    "total_p = float(total[\"Dead\"])\n",
    "mushrooms = [total_e, total_p]\n",
    "mushrooms_labels = 'Survived','Dead'\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "plt.pie(mushrooms,labels=mushrooms,autopct='%1.1f%%',colors = ['#88d14f', '#f23d3a'])\n",
    "plt.title('Dataset Balancing', loc = \"center\", fontsize=\"20\")\n",
    "plt.axis('equal')\n",
    "plt.legend(mushrooms_labels,bbox_to_anchor=(0.6, -0.05, 0, 0))\n",
    "fig.set_facecolor('white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo, come già visto nell'analisi preliminare porta il modello a classificare più frequentemente le classi come 'survived', in quanto ha molti più dati in percentuale su cui effettuare il training. Per questo si possono applicare diverse strategie per cercare di ripristinare il bilanciamento del dataset:\n",
    "\n",
    "- Oversampling\n",
    "- SMOTE\n",
    "- Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "num_survd = (trainY== 0).sum()\n",
    "num_death = (trainY== 1).sum()\n",
    "\n",
    "num_under = num_survd - num_death\n",
    "print (\"Removing\",num_under,\"istances\")\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "trainX_und,trainY_und = rus.fit_resample(trainX_og.fillna(-1),trainY.fillna(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo dai risultati che peggiorano tutte le metriche applicando il balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifications(trainX_und,trainY_und,testX_og,testY,fill=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come atteso migliorano effettivamente le classificazioni di classi 'death' rispetto a 'survived'. Tuttavia rimuovendo 60882 istanze dal training set si ha una significativa perdita di informazioni, che porta l'accuracy del modello a decrescere significativamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "num_survd = (trainY== 0).sum()\n",
    "num_death = (trainY== 1).sum()\n",
    "\n",
    "num_under = num_survd - num_death\n",
    "print (\"Creating\",num_under,\"istances\")\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "trainX_ov,trainY_ov = ros.fit_resample(trainX_og.fillna(-1),trainY.fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_classifications(trainX_ov,trainY_ov,testX_og,testY,fill=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel dettaglio, sono stati analizzati i risultati ottenuti dai seguenti modelli:\n",
    "- Logistic Regression Classifier\n",
    "- Decision Tree Classifier\n",
    "- Gaussian Naive Bayes Classifier\n",
    "- Random Forest Classifier\n",
    "- AdaBoost Classifier\n",
    "- Linear Discriminant Analysis\n",
    "\n",
    "Di seguito i risultati di diversi classificatori applicati sul training set dopo il processo di feature tweaking, senza considerare l'imputazione dei dati, la PCA e il sampling, tecniche che peggiorano gli score causando perdita di informazioni significative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = LogisticRegression(solver=\"liblinear\")\n",
    "run_classifications(trainX,trainY,testX,testY, fill = True, \n",
    "        model=lrc, model_name=\"Logistic Regression Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "run_classifications(trainX,trainY,testX,testY, fill = True, \n",
    "        model=dtc, model_name=\"Decision Tree Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "run_classifications(trainX,trainY,testX,testY, fill = True, \n",
    "        model=dtc, model_name=\"Gaussian Naive Bayes Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "run_classifications(trainX,trainY,testX,testY, fill = True, \n",
    "        model=rfc, model_name=\"Random Forest Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "run_classifications(trainX,trainY,testX,testY, fill = True, \n",
    "        model=abc, model_name=\"AdaBoost Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "run_classifications(trainX,trainY,testX,testY, fill = True, \n",
    "        model=rfc, model_name=\"Linear Discriminant Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un iperparametro (non so se è iperparametro) delle SVM è la funzione Kernel che andrà ad utilizzare nell'individuazione dell'iperpiano di separazione. La principali funzioni kernel messe a disposizione dal framework sklearn sono:\n",
    "- lineare\n",
    "- polimoniale\n",
    "- rbf\n",
    "- sigmoide\n",
    "\n",
    "Nel nostro caso, probabilmente le istanze survived e death non saranno linearmente separabili (ed infatti la computazione con kernel lineare non termina perchè non riesce a trovare un iperpiano di separazione lineare). Per tale motivo si è scelto di utilizzare un kernel polimoniale.\n",
    "Ci mette tanto pure polimoniale  \n",
    "\n",
    "TODO Sarebbe da valutare le prestazione del modell al variare degli iper parametri tramite una GridSearch, anche lui lo fa in Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainX,trainY,testX,testY\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_classifier = SVC(kernel='poly')\n",
    "\n",
    "run_classifications(trainX, trainY, testX, testY, fill=True, model=svc_classifier, model_name='SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier = SVC(kernel='rbf')            # senza calcolare le probabilità dovrebbe essere più veloce\n",
    "\n",
    "#run_classifications(trainX, trainY, testX, testY, fill=True, model=svc_classifier, model_name='SVC')\n",
    "\n",
    "svc_classifier.fit(trainX, trainY)\n",
    "svm_predict_targets = svc_classifier.predict(testX)\n",
    "svm_cm = confusion_matrix(testY, svm_predict_targets)\n",
    "\n",
    "x_axis_labels = [\"Survived\", \"Dead\"]\n",
    "y_axis_labels = [\"Survived\", \"Dead\"]\n",
    "f, ax = plt.subplots(figsize =(7,7))\n",
    "sns.heatmap(cm, annot = True, linewidths=0.2, linecolor=\"black\", fmt = \".0f\", ax=ax, cmap=\"Reds\", xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "plt.xlabel(\"PREDICTED LABEL\")\n",
    "plt.ylabel(\"TRUE LABEL\")\n",
    "plt.title('Confusion Matrix for {} Classifier'.format(model[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = trainX.columns.values\n",
    "feature_importance = dt.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center', color =\"red\")\n",
    "plt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature importance')\n",
    "plt.draw()\n",
    "#plt.savefig(\"featureimp.png\", format='png', dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd33f47137b00f9a3c223ad7cd7ea8009173bfffa8c9627ff61bae578e5b56e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
